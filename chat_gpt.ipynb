{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7fa3ee9-62ba-4849-9f83-8584139e295f",
   "metadata": {},
   "source": [
    "## ChatGPT\n",
    "\n",
    "This is just some messing around."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6baf77f-b887-437d-b0c6-20cde719d906",
   "metadata": {},
   "source": [
    "Docs:\n",
    "\n",
    "* how to upload images: https://platform.openai.com/docs/guides/vision\n",
    "* types of models: https://stackoverflow.com/questions/75774873/openai-api-error-this-is-a-chat-model-and-not-supported-in-the-v1-completions\n",
    "* token limits: https://platform.openai.com/settings/organization/limits\n",
    "* models: https://platform.openai.com/docs/models/model-endpoint-compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f25dda74-0b62-4a27-9566-aaaa27727c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a2cf577c-4a80-4fbf-b4a0-8a0a61d16b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import base64\n",
    "from openai import OpenAI\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fc26f67-1869-44f7-97bb-238b2c5a42b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    img = Image.open(image_path).convert('RGB')\n",
    "    new_size = np.round(np.array(img.size)*0.5).astype('int')\n",
    "    img = img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "    #img = np.array(img)\n",
    "    #with open(image_path, \"rb\") as image_file:\n",
    "    img.save('/Users/jnaiman/Downloads/tmp/tmp_img.png')\n",
    "    with open('/Users/jnaiman/Downloads/tmp/tmp_img.png','rb') as image_file:\n",
    "        #return base64.b64encode(img).decode(\"utf-8\")\n",
    "        return base64.b64encode(image_file.read()).decode(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea00bfbc-d960-466e-9812-4bca17a8b760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get image\n",
    "image_path = '/Users/jnaiman/Downloads/data_full_v2/Picture1.png'\n",
    "encoded_image = load_image(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dbcbf789-044b-445c-bb90-749124f66e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: What is happening in this image?\n",
      "A: The image appears to be a graphical representation of data, likely from an experiment or study. It features a line graph with multiple data series plotted against a common x-axis labeled \"MATERIAL CORRECTION\" and a y-axis labeled \"BEHAVIOUR DOUBT.\"\n",
      "\n",
      "Here are a few observations:\n",
      "\n",
      "- There are four different lines, each represented by a different color and style (solid, dashed, dotted).\n",
      "- The y-axis values range from 0 to about 150.\n",
      "- The x-axis ranges from 2 to 14.\n",
      "- It seems that these lines could be showing different measurements or responses related to how behavior doubt changes with material correction.\n",
      "\n",
      "Overall, this graph involves a comparative analysis of how behavior doubt varies with material correction across different conditions or treatments, represented by the colored lines.\n",
      "\n",
      "Q: What is the main object in this image?\n",
      "A: The main object in the image is a line graph that illustrates data related to \"BEHAVIOUR DOUBT\" against \"MATERIAL CORRECTION.\" The graph includes multiple trend lines in different colors, each representing different datasets or variables. The x-axis is labeled \"MATERIAL CORRECTION,\" and the y-axis is labeled \"BEHAVIOUR DOUBT.\" The data points are connected with lines, showing trends over the range of material correction values.\n",
      "\n",
      "Q: Can you describe the colors in this image?\n",
      "A: The image contains a line graph with several distinct colored lines representing different data series. The colors present in the graph are:\n",
      "\n",
      "1. **Red** - This line represents one of the data series and appears to be the highest or has the most significant upward trend.\n",
      "2. **Green** - This line has a dashed style and indicates another data series with fluctuating values.\n",
      "3. **Purple** - This line appears in a dotted style and showcases a different trend compared to the others.\n",
      "4. **Orange** - This line is also in a dotted style and shows a downward trend as the x-axis values increase.\n",
      "5. **Blue** - This line is solid and suggests a stable trend across the data points.\n",
      "\n",
      "The graph has a white background with black axes and grid lines to enhance readability.\n",
      "\n",
      "Q: Does this image contain any text? If so, what does it say?\n",
      "A: Yes, the image contains text. Here is what it says:\n",
      "\n",
      "- The y-axis is labeled \"BEHAVIOUR DOUBT.\"\n",
      "- The x-axis is labeled \"MATERIAL CORRECTION\" with a notation that says \"d_eff = 100.\"\n",
      "- There are different colored lines representing various data trends in the graph, but specific descriptions of these lines are not included in the visible text.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "with open('/Users/jnaiman/.openai/key.txt','r') as f:\n",
    "    api_key = f.read()\n",
    "\n",
    "client = OpenAI(\n",
    "  api_key=api_key.strip(),  # this is also the default, it can be omitted\n",
    ")\n",
    "\n",
    "#############\n",
    "\n",
    "# Step 3: Ask a series of questions\n",
    "questions = [\n",
    "    \"What is happening in this image?\",\n",
    "    \"What is the main object in this image?\",\n",
    "    \"Can you describe the colors in this image?\",\n",
    "    \"Does this image contain any text? If so, what does it say?\"\n",
    "]\n",
    "\n",
    "responses = []\n",
    "\n",
    "for question in questions:\n",
    "    # Prepare the API request\n",
    "    prompt = f\"I am going to show you an image. Here is the image: [Image: {encoded_image}]. Now, {question}\"\n",
    "    \n",
    "    # Send the request to the GPT-4o API\n",
    "    response = client.chat.completions.create(\n",
    "        #model=\"gpt-4\",\n",
    "        #model=\"gpt-4o\",\n",
    "        model =\"gpt-4o-mini\",\n",
    "        #model =\"gpt-3.5-turbo\",\n",
    "        #model=\"gpt-3.5-turbo-instruct\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant that can analyze images.\"},\n",
    "            {\"role\":\"user\", \"content\": [\n",
    "                {\n",
    "                  \"type\": \"text\",\n",
    "                  \"text\": prompt\n",
    "                },\n",
    "                {\n",
    "                  \"type\": \"image_url\",\n",
    "                  \"image_url\": {\n",
    "                    \"url\": f\"data:image/jpeg;base64,{encoded_image}\"\n",
    "                  }\n",
    "                }\n",
    "            ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Get the response from the API\n",
    "    #answer = response.choices[0].text #response.choices[0].message[\"content\"]\n",
    "    answer = response.choices[0].message.content\n",
    "    responses.append((question, answer))\n",
    "\n",
    "# Step 4: Handle the responses\n",
    "for question, answer in responses:\n",
    "    print(f\"Q: {question}\\nA: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1a020d67-8454-40fa-baed-18f336154d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.chat.completions.create?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "717d9de6-bade-41f6-8662-73cc9b5a5b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# payload = {\n",
    "#   \"model\": \"gpt-4o-mini\",\n",
    "#   \"messages\": [\n",
    "#     {\n",
    "#       \"role\": \"user\",\n",
    "#       \"content\": [\n",
    "#         {\n",
    "#           \"type\": \"text\",\n",
    "#           \"text\": \"Whatâ€™s in this image?\"\n",
    "#         },\n",
    "#         {\n",
    "#           \"type\": \"image_url\",\n",
    "#           \"image_url\": {\n",
    "#             \"url\": f\"data:image/jpeg;base64,{base64_image}\"\n",
    "#           }\n",
    "#         }\n",
    "#       ]\n",
    "#     }\n",
    "#   ],\n",
    "#   \"max_tokens\": 300\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad96240d-d389-4e4f-b204-dd95152fba45",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
